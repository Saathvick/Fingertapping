{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap 1: Count = 1, Max Amplitude = 0.020705863627997822, Frozen Time = 0.0\n",
      "Tap 2: Count = 2, Max Amplitude = 0.2187034307201529, Frozen Time = 0.5740337371826172\n",
      "Tap 3: Count = 3, Max Amplitude = 0.30565139158505333, Frozen Time = 0.0781564712524414\n",
      "Tap 4: Count = 4, Max Amplitude = 0.20189977274701124, Frozen Time = 0.07479405403137207\n",
      "4 , 0.18674011467005383 , 0.18174606561660767\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "tap_count_list = [] \n",
    "max_amplitude_list = []  \n",
    "frozen_time_list = [] \n",
    "\n",
    "tapping_count = 0\n",
    "prev_touching = False\n",
    "max_amplitude = 0\n",
    "frozen_start_time = None\n",
    "threshold = 0.1\n",
    "\n",
    "start_time = None  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if start_time is None:  \n",
    "        start_time = time.time()\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time >= 5:\n",
    "        break\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        thumb = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "        index_finger = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        distance = np.linalg.norm(np.array([thumb.x, thumb.y]) - np.array([index_finger.x, index_finger.y]))\n",
    "\n",
    "        if distance > max_amplitude:\n",
    "            max_amplitude = distance\n",
    "            frozen_start_time = time.time()\n",
    "\n",
    "        touching = distance < threshold\n",
    "\n",
    "        if not prev_touching and touching:\n",
    "            tapping_count += 1\n",
    "            tap_count_list.append(tapping_count)\n",
    "            max_amplitude_list.append(max_amplitude)\n",
    "            max_amplitude = 0\n",
    "\n",
    "            if frozen_start_time is not None:\n",
    "                frozen_time = time.time() - frozen_start_time\n",
    "                frozen_time_list.append(frozen_time)\n",
    "            frozen_start_time = None\n",
    "        \n",
    "        prev_touching = touching\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        x_min = int(min([lm.x * frame.shape[1] for lm in hand_landmarks.landmark]))\n",
    "        y_min = int(min([lm.y * frame.shape[0] for lm in hand_landmarks.landmark]))\n",
    "        x_max = int(max([lm.x * frame.shape[1] for lm in hand_landmarks.landmark]))\n",
    "        y_max = int(max([lm.y * frame.shape[0] for lm in hand_landmarks.landmark]))\n",
    "\n",
    "        # Draw rectangle around the hand\n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    text_size = 0.5\n",
    "    text_thickness = 1\n",
    "    text_x = 10\n",
    "    text_y = 20\n",
    "    text_y_offset = 20\n",
    "\n",
    "    cv2.putText(frame, f\"Tapping Count: {tapping_count}\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                (0, 255, 0), text_thickness)\n",
    "    cv2.putText(frame, f\"Amplitude: {max_amplitude:.2f}\", (text_x, text_y + text_y_offset), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                text_size, (0, 255, 0), text_thickness)\n",
    "    cv2.imshow('Finger Tapping', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('s'):  \n",
    "        start_time = time.time()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "for i in range(len(tap_count_list)):\n",
    "    print(f\"Tap {i+1}: Count = {tap_count_list[i]}, Max Amplitude = {max_amplitude_list[i]}, Frozen Time = {frozen_time_list[i]}\")\n",
    "avg_max_amp = sum(max_amplitude_list)/len(max_amplitude_list)\n",
    "##keke\n",
    "avg_frozen_time = sum(frozen_time_list)/len(frozen_time_list)\n",
    "#find the highest tap\n",
    "max_count = max(tap_count_list)\n",
    "print(max_count,\",\",avg_max_amp, \",\", avg_frozen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv('C:/Users/Kannan/Documents/FT/leftfeapark.csv')\n",
    "X = df[['Count', 'Average Max Amplitude', 'Average Frozen Time']]\n",
    "y = df['Level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=688)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "class_distribution_resampled = pd.Series(y_train_resampled).value_counts()\n",
    "# print(\"\\nClass distribution in training set after SMOTE:\")\n",
    "# print(class_distribution_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted level is: 1\n",
      "12 0.21804857888851834 0.16620184977849325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kannan\\anaconda3\\envs\\GG_3486\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_observation = [[max_count , avg_max_amp ,avg_frozen_time ]]\n",
    "\n",
    "new_observation = scaler.transform(new_observation)\n",
    "\n",
    "predicted_level = model.predict(new_observation)\n",
    "\n",
    "print(\"The predicted level is:\", predicted_level[0])\n",
    "print(max_count, avg_max_amp,avg_frozen_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_3486",
   "language": "python",
   "name": "gg_3486"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
