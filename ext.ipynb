{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tap 1: Count = 1, Max Amplitude = 0.22653683575398115, Frozen Time = 0.16541695594787598\n",
      "Tap 2: Count = 2, Max Amplitude = 0.11749643158358097, Frozen Time = 0.0808420181274414\n",
      "Tap 3: Count = 3, Max Amplitude = 0.15338892610604116, Frozen Time = 0.1387169361114502\n",
      "Tap 4: Count = 4, Max Amplitude = 0.23990768905847928, Frozen Time = 0.14049124717712402\n",
      "Tap 5: Count = 5, Max Amplitude = 0.18275179758265403, Frozen Time = 0.15441012382507324\n",
      "Tap 6: Count = 6, Max Amplitude = 0.10913614966061433, Frozen Time = 0.0772697925567627\n",
      "Tap 7: Count = 7, Max Amplitude = 0.15322453877955902, Frozen Time = 0.06402349472045898\n",
      "Tap 8: Count = 8, Max Amplitude = 0.180481146011606, Frozen Time = 0.1538994312286377\n",
      "Tap 9: Count = 9, Max Amplitude = 0.11639873875140508, Frozen Time = 0.0639183521270752\n",
      "Tap 10: Count = 10, Max Amplitude = 0.13660865149042034, Frozen Time = 0.14071059226989746\n",
      "Tap 11: Count = 11, Max Amplitude = 0.2531748936635332, Frozen Time = 0.07902288436889648\n",
      "Tap 12: Count = 12, Max Amplitude = 0.13409154889924246, Frozen Time = 0.05435466766357422\n",
      "Tap 13: Count = 13, Max Amplitude = 0.20841479332589732, Frozen Time = 0.07780122756958008\n",
      "Tap 14: Count = 14, Max Amplitude = 0.10323050548191956, Frozen Time = 0.07627487182617188\n",
      "Tap 15: Count = 15, Max Amplitude = 0.11871911184745722, Frozen Time = 0.06618380546569824\n",
      "Tap 16: Count = 16, Max Amplitude = 0.15072867372935614, Frozen Time = 0.1612555980682373\n",
      "Tap 17: Count = 17, Max Amplitude = 0.18309702738951997, Frozen Time = 0.2787950038909912\n",
      "17 , 0.1627874975950157 , 0.11608158840852625\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "mp_hands = mp.solutions.hands\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "hands = mp_hands.Hands()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "tap_count_list = [] \n",
    "max_amplitude_list = []  \n",
    "frozen_time_list = [] \n",
    "\n",
    "tapping_count = 0\n",
    "prev_touching = False\n",
    "max_amplitude = 0\n",
    "frozen_start_time = None\n",
    "threshold = 0.1\n",
    "\n",
    "start_time = None  \n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    if start_time is None:  \n",
    "        start_time = time.time()\n",
    "\n",
    "    elapsed_time = time.time() - start_time\n",
    "    if elapsed_time >= 5:\n",
    "        break\n",
    "\n",
    "    image_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    results = hands.process(image_rgb)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        hand_landmarks = results.multi_hand_landmarks[0]\n",
    "        thumb = hand_landmarks.landmark[mp_hands.HandLandmark.THUMB_TIP]\n",
    "        index_finger = hand_landmarks.landmark[mp_hands.HandLandmark.INDEX_FINGER_TIP]\n",
    "        distance = np.linalg.norm(np.array([thumb.x, thumb.y]) - np.array([index_finger.x, index_finger.y]))\n",
    "\n",
    "        if distance > max_amplitude:\n",
    "            max_amplitude = distance\n",
    "            frozen_start_time = time.time()\n",
    "\n",
    "        touching = distance < threshold\n",
    "\n",
    "        if not prev_touching and touching:\n",
    "            tapping_count += 1\n",
    "            tap_count_list.append(tapping_count)\n",
    "            max_amplitude_list.append(max_amplitude)\n",
    "            max_amplitude = 0\n",
    "\n",
    "            if frozen_start_time is not None:\n",
    "                frozen_time = time.time() - frozen_start_time\n",
    "                frozen_time_list.append(frozen_time)\n",
    "            frozen_start_time = None\n",
    "        \n",
    "        prev_touching = touching\n",
    "\n",
    "        # Calculate bounding box coordinates\n",
    "        x_min = int(min([lm.x * frame.shape[1] for lm in hand_landmarks.landmark]))\n",
    "        y_min = int(min([lm.y * frame.shape[0] for lm in hand_landmarks.landmark]))\n",
    "        x_max = int(max([lm.x * frame.shape[1] for lm in hand_landmarks.landmark]))\n",
    "        y_max = int(max([lm.y * frame.shape[0] for lm in hand_landmarks.landmark]))\n",
    "\n",
    "       \n",
    "        cv2.rectangle(frame, (x_min, y_min), (x_max, y_max), (0, 255, 0), 2)\n",
    "\n",
    "    if results.multi_hand_landmarks:\n",
    "        for hand_landmarks in results.multi_hand_landmarks:\n",
    "            mp_drawing.draw_landmarks(frame, hand_landmarks, mp_hands.HAND_CONNECTIONS)\n",
    "\n",
    "    text_size = 0.5\n",
    "    text_thickness = 1\n",
    "    text_x = 10\n",
    "    text_y = 20\n",
    "    text_y_offset = 20\n",
    "\n",
    "    cv2.putText(frame, f\"Tapping Count: {tapping_count}\", (text_x, text_y), cv2.FONT_HERSHEY_SIMPLEX, text_size,\n",
    "                (0, 255, 0), text_thickness)\n",
    "    cv2.putText(frame, f\"Amplitude: {max_amplitude:.2f}\", (text_x, text_y + text_y_offset), cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                text_size, (0, 255, 0), text_thickness)\n",
    "    cv2.imshow('Finger Tapping', frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    elif cv2.waitKey(1) & 0xFF == ord('s'):  \n",
    "        start_time = time.time()\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "for i in range(len(tap_count_list)):\n",
    "    print(f\"Tap {i+1}: Count = {tap_count_list[i]}, Max Amplitude = {max_amplitude_list[i]}, Frozen Time = {frozen_time_list[i]}\")\n",
    "avg_max_amp = sum(max_amplitude_list)/len(max_amplitude_list)\n",
    "##keke\n",
    "avg_frozen_time = sum(frozen_time_list)/len(frozen_time_list)\n",
    "#find the highest tap\n",
    "max_count = max(tap_count_list)\n",
    "print(max_count,\",\",avg_max_amp, \",\", avg_frozen_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96        12\n",
      "           1       0.96      0.81      0.88        27\n",
      "           2       0.90      0.88      0.89        32\n",
      "           3       0.43      1.00      0.60         3\n",
      "\n",
      "    accuracy                           0.88        74\n",
      "   macro avg       0.80      0.92      0.83        74\n",
      "weighted avg       0.91      0.88      0.89        74\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "df = pd.read_csv('C:/Users/Kannan/Documents/FT/leftfeapark.csv')\n",
    "X = df[['Count', 'Average Max Amplitude', 'Average Frozen Time']]\n",
    "y = df['Level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=688)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "smote = SMOTE(sampling_strategy='not majority', random_state=42)\n",
    "X_train_resampled, y_train_resampled = smote.fit_resample(X_train_scaled, y_train)\n",
    "\n",
    "model = DecisionTreeClassifier(max_depth=2)\n",
    "model.fit(X_train_resampled, y_train_resampled)\n",
    "\n",
    "\n",
    "y_pred = model.predict(X_test_scaled)\n",
    "\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "\n",
    "class_distribution_resampled = pd.Series(y_train_resampled).value_counts()\n",
    "# print(\"\\nClass distribution in training set after SMOTE:\")\n",
    "# print(class_distribution_resampled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The predicted level is: 0\n",
      "17 0.1627874975950157 0.11608158840852625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Kannan\\anaconda3\\envs\\GG_3486\\lib\\site-packages\\sklearn\\base.py:464: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "new_observation = [[max_count , avg_max_amp ,avg_frozen_time ]]\n",
    "\n",
    "new_observation = scaler.transform(new_observation)\n",
    "\n",
    "predicted_level = model.predict(new_observation)\n",
    "\n",
    "print(\"The predicted level is:\", predicted_level[0])\n",
    "print(max_count, avg_max_amp,avg_frozen_time)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GG_3486",
   "language": "python",
   "name": "gg_3486"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
